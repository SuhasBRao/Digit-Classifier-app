{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCXU7CCaTpo0iDIkwJuYbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuhasBRao/Digit-Classifier-app/blob/main/Digit_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GoinpDof8t4n"
      },
      "outputs": [],
      "source": [
        "#### PACKAGE IMPORTS ####\n",
        "\n",
        "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to load the MNIST data\n",
        "\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa6gFQhE85Fw",
        "outputId": "3ea4983e-0fa8-4a36-a081-6129b4205960"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_mnist_data(train_images, test_images):\n",
        "    \"\"\"\n",
        "    This function takes in the training and test images as loaded in the cell above, and scales them\n",
        "    so that they have minimum and maximum values equal to 0 and 1 respectively.\n",
        "    Your function should return a tuple (train_images, test_images) of scaled training and test images.\n",
        "    \"\"\"\n",
        "    train_images = train_images / 255.\n",
        "    test_images = test_images / 255.\n",
        "    return (train_images, test_images)"
      ],
      "metadata": {
        "id": "HXi8xjcb88RJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your function on the input data\n",
        "\n",
        "scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images)"
      ],
      "metadata": {
        "id": "ObCGPi189AGe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a dummy channel dimension\n",
        "\n",
        "scaled_train_images = scaled_train_images[..., np.newaxis]\n",
        "scaled_test_images = scaled_test_images[..., np.newaxis]"
      ],
      "metadata": {
        "id": "Kyf_hqkl9CQS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(input_shape):\n",
        "    \"\"\"\n",
        "    This function should build a Sequential model according to the above specification. Ensure the \n",
        "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(8, kernel_size = (3,3), \\\n",
        "                activation = 'relu', padding = 'same', input_shape = input_shape))\n",
        "    model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense (64, activation = 'relu')) \n",
        "    model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "pjMOMxaS9D-a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(scaled_train_images[0].shape)"
      ],
      "metadata": {
        "id": "b9uSw39e9I_-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(model):\n",
        "    \"\"\"\n",
        "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
        "    loss function and metric.\n",
        "    Compile the model using the Adam optimiser (with default settings), the cross-entropy loss function and\n",
        "    accuracy as the only metric. \n",
        "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
        "    \"\"\"\n",
        "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', \n",
        "                 metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "g88MwUzn9Lhn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your function to compile the model\n",
        "\n",
        "compile_model(model)"
      ],
      "metadata": {
        "id": "AvSAHLHe9PCz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, scaled_train_images, train_labels):\n",
        "    \"\"\"\n",
        "    This function should train the model for 5 epochs on the scaled_train_images and train_labels. \n",
        "    Your function should return the training history, as returned by model.fit.\n",
        "    \"\"\"\n",
        "    history = model.fit(scaled_train_images, train_labels, epochs = 5)\n",
        "    return history"
      ],
      "metadata": {
        "id": "ECMxuI5H9QyG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model, scaled_train_images, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JzEMNl19TVP",
        "outputId": "f3302cb5-48d1-4105-8a91-de7d3c6e2003"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2197 - accuracy: 0.9344\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0758 - accuracy: 0.9766\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0511 - accuracy: 0.9845\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0381 - accuracy: 0.9876\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0283 - accuracy: 0.9907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, scaled_test_images, test_labels):\n",
        "    \"\"\"\n",
        "    This function should evaluate the model on the scaled_test_images and test_labels. \n",
        "    Your function should return a tuple (test_loss, test_accuracy).\n",
        "    \"\"\"\n",
        "    test_loss, test_accuracy = model.evaluate(scaled_test_images, test_labels)\n",
        "    return (test_loss, test_accuracy)"
      ],
      "metadata": {
        "id": "opzxyQql9WRe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your function to evaluate the model\n",
        "\n",
        "test_loss, test_accuracy = evaluate_model(model, scaled_test_images, test_labels)\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvbPcneW95EW",
        "outputId": "22dbe325-babf-4d27-ae5a-ed7808d4b58a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0658 - accuracy: 0.9795\n",
            "Test loss: 0.06581363826990128\n",
            "Test accuracy: 0.9794999957084656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Digit_classifier.h5')"
      ],
      "metadata": {
        "id": "3v--SQJu9_9K"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}